import streamlit as st
import pandas as pd
import numpy as np
import pickle
import joblib
from tensorflow.keras.models import load_model
import glob

# =====================================================
# 1Ô∏è‚É£ Titre et chargement des mod√®les
# =====================================================
st.title("üìä Pr√©diction des retraits GAB (Prophet + LSTM)")

# --- Charger le mod√®le LSTM ---
lstm_model = load_model("lstm_model.h5", compile=False)

# --- Charger les scalers ---
scaler_X = joblib.load("scaler_X.pkl")
scaler_y = joblib.load("scaler_y.pkl")

# --- Charger les mod√®les Prophet par cluster ---
prophet_models = {}
for file in glob.glob("prophet_model_cluster_*.pkl"):
    cluster_id = int(file.split("_")[-1].split(".")[0])
    with open(file, "rb") as f:
        prophet_models[cluster_id] = pickle.load(f)

st.success("‚úÖ Mod√®les charg√©s avec succ√®s !")

# =====================================================
# 2Ô∏è‚É£ Entr√©e utilisateur pour pr√©diction individuelle
# =====================================================
num_gab = st.number_input("üìå Num√©ro du GAB", min_value=0, step=1)
date_arrete = st.date_input("üìÖ Date √† pr√©dire")

# --- Mapping num_gab ‚Üí cluster (√† adapter selon ton fichier CSV) ---
# Si tu as un CSV avec tous les GABs et clusters, tu peux le charger ici
# Exemple fictif :
gab_cluster_mapping = {
    101: 0,
    102: 1,
    103: 2,
    # ... compl√©ter avec tous les GABs
}

if num_gab not in gab_cluster_mapping:
    st.warning("‚ö†Ô∏è Num√©ro de GAB inconnu !")
else:
    cluster_id = gab_cluster_mapping[num_gab]
    
    # --- Pr√©vision Prophet ---
    model_prophet = prophet_models[cluster_id]
    future = model_prophet.make_future_dataframe(periods=1)
    forecast = model_prophet.predict(future)
    yhat = forecast[forecast['ds'] == pd.to_datetime(date_arrete)]['yhat'].values
    if len(yhat) == 0:
        st.warning("‚ö†Ô∏è Date en dehors de l'horizon de pr√©diction Prophet !")
    else:
        yhat = yhat[0]

        # --- Pr√©vision LSTM sur les r√©sidus ---
        # Ici, il faut les derniers r√©sidus connus pour ce GAB
        # Exemple fictif : si tu n‚Äôas pas encore de CSV historique, on initialise √† 0
        time_steps = 14
        last_resid = np.zeros(time_steps)  # remplacer par les vrais r√©sidus si disponibles

        # Pr√©parer l‚Äôentr√©e pour le LSTM
        X_input = scaler_X.transform(last_resid.reshape(1, -1)).reshape(1, time_steps, 1)
        y_resid_pred_scaled = lstm_model.predict(X_input)
        y_resid_pred = scaler_y.inverse_transform(y_resid_pred_scaled).flatten()[0]

        # --- Montant final pr√©dit ---
        montant_pred_final = yhat + y_resid_pred

        st.subheader("üí∞ Pr√©diction finale pour ce GAB et cette date")
        st.write(f"Montant pr√©vu : {montant_pred_final:.2f} DH")
